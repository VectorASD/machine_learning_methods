{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49128413-b11c-454c-936c-d0b8e8dfae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist # pip install keras tensorflow\n",
    "import matplotlib.pyplot as plt # pip install matplotlib\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, GaussianDropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Вариант задания: Распознавание цифр на изображении (MNIST digits classification dataset)\n",
    "# Нейросеть должна состоять из четырех полносвязных слоёв,\n",
    "# обязательное использование GaussianDropout,\n",
    "# в качестве оптимизатора использовать SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991ba5e6-39de-46b1-bc29-763b7a2a4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c18b33-80bd-4900-a7c4-50e6a39c0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ba0168-9c10-4432-875e-f1f7f40824c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">567,434</span> (2.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m567,434\u001b[0m (2.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/schmoyote/guide-to-mnist-digit-classification-with-keras\n",
    "# версия самих разработчиков mnist\n",
    "def mnist_version_model_builder():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(784,)))\n",
    "    model.add(Dense(units=128, activation=\"relu\")) # ReLU -> σ(x) = max(0, x)\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# моя версия под собственный вариант задания\n",
    "def my_version_model_builder():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(784,)))\n",
    "    model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5)) # GaussianDropout = Dropout(0.5)\n",
    "    model.add(Dense(units=256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=10, activation=\"softmax\"))  # Выходной слой\n",
    "\n",
    "    sgd = SGD(learning_rate = 0.01, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "#model = mnist_version_model_builder()\n",
    "model = my_version_model_builder()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba7499a-2a9f-4ab1-8fc3-894dfb1eee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>, <Dropout name=dropout_1, built=True>, <Dense name=dense_2, built=True>, <Dropout name=dropout_2, built=True>, <Dense name=dense_3, built=True>]\n",
      "(784, 512) float32\n",
      "(512,) float32\n",
      "(512, 256) float32\n",
      "(256,) float32\n",
      "(256, 128) float32\n",
      "(128,) float32\n",
      "(128, 10) float32\n",
      "(10,) float32\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)\n",
    "for W in model.get_weights(): print(W.shape, W.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e00728-0049-4a88-99f4-45bb980ee14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='accuracy', patience=float(\"inf\"), verbose=1, mode='max', baseline=0.9999, restore_best_weights=True)\n",
    "# - monitor: Метрическая величина, которую вы хотите отслеживать. В данном случае вы можете использовать `accuracy`.\n",
    "# - patience: Количество эпох, которое нужно ждать, если метрика не улучшается, прежде чем остановить обучение. Если вы установите его в 0, обучение остановится сразу при достижении точности 0.9999.\n",
    "# - verbose: Уровень отображения информации о процессе остановки. Установив его в 1, вы получите текстовый вывод. \n",
    "# - mode: Режим отслеживания. 'max' указывает, что нужно остановить обучение, если точность достигает максимума.\n",
    "# - baseline: Начальное значение для метрики. В данном случае мы устанавливаем его в 0.9999, чтобы остановить обучение, если метрика достигает этого значения.\n",
    "# - restore_best_weights: Если `True`, то веса модели будут восстановлены на уровне, который соответствует лучшему значению `monitor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdbabf8-1dd9-4d54-9db1-c0262fed64fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0096\n",
      "Epoch 2/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0103\n",
      "Epoch 3/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0097\n",
      "Epoch 4/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0093\n",
      "Epoch 5/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0111\n",
      "Epoch 6/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0110\n",
      "Epoch 7/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0101\n",
      "Epoch 8/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0101\n",
      "Epoch 9/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0108\n",
      "Epoch 10/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0090\n",
      "Epoch 11/11\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0106\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 7.3813e-05\n",
      "{'accuracy': [0.997083306312561, 0.9967333078384399, 0.9972000122070312, 0.9972500205039978, 0.9968666434288025, 0.9965166449546814, 0.9968666434288025, 0.9968166947364807, 0.9970333576202393, 0.9970166683197021, 0.996833324432373], 'loss': [0.010236565954983234, 0.010961719788610935, 0.010241738520562649, 0.00929287914186716, 0.010134623385965824, 0.010710430331528187, 0.00948254857212305, 0.010337993502616882, 0.010291517712175846, 0.009772158227860928, 0.010913560166954994]} 0.9972500205039978 8.277646702481434e-05 1.0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "epochs = 11\n",
    "while True:\n",
    "    history = model.fit(x=X_train, y=y_train, batch_size = BATCH_SIZE, epochs = epochs, verbose=1, callbacks=[early_stopping])\n",
    "    acc = max(history.history[\"accuracy\"])\n",
    "    if acc > 0.99: train_loss, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "    else: train_loss = train_acc = -1 \n",
    "    print(history.history, acc, train_loss, train_acc)\n",
    "    if acc > 0.9999 or train_acc > 0.9999: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1495942-2a28-4d99-8d1e-7355e5b76057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n",
      "(5, 784)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[[0.0000 0.0000 0.0001 0.0001 0.0000 0.0000 0.0000 0.0000 0.9998 0.0000]\n",
      " [0.0000 0.0000 0.0001 0.0001 0.0000 0.0000 0.0000 0.0000 0.9998 0.0000]\n",
      " [0.0000 0.0000 0.0001 0.0001 0.0000 0.0000 0.0000 0.0000 0.9998 0.0000]\n",
      " [0.0000 0.0000 0.0001 0.0001 0.0000 0.0000 0.0000 0.0000 0.9998 0.0000]\n",
      " [0.0000 0.0000 0.0001 0.0001 0.0000 0.0000 0.0000 0.0000 0.9998 0.0000]]\n",
      "<KerasTensor shape=(None, 784), dtype=float32, sparse=False, name=input_layer>\n",
      "<KerasTensor shape=(None, 512), dtype=float32, sparse=False, name=keras_tensor_174>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "Activation of layer 0: shape (1, 512)\n",
      "Activation of layer 1: shape (1, 512)\n",
      "Activation of layer 2: shape (1, 256)\n",
      "Activation of layer 3: shape (1, 256)\n",
      "Activation of layer 4: shape (1, 128)\n",
      "Activation of layer 5: shape (1, 128)\n",
      "Activation of layer 6: shape (1, 10)\n",
      "Weights of layer 0: shape (784, 512), biases shape (512,)\n",
      "Weights of layer 2: shape (512, 256), biases shape (256,)\n",
      "Weights of layer 4: shape (256, 128), biases shape (128,)\n",
      "Weights of layer 6: shape (128, 10), biases shape (10,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={\"float_kind\": \"{:.4f}\".format})\n",
    "#image = np.random.rand(28, 28).astype(np.float32)\n",
    "#print(tuple(tuple(round(x * 255) for x in row) for row in image))\n",
    "image = np.array(((41, 148, 2, 80, 128, 191, 188, 115, 125, 96, 16, 128, 157, 10, 227, 44, 183, 197, 59, 249, 254, 39, 116, 58, 118, 120, 51, 78), (78, 188, 163, 202, 213, 116, 80, 122, 75, 235, 116, 18, 48, 31, 143, 207, 223, 92, 57, 87, 12, 181, 202, 82, 143, 119, 69, 38), (83, 113, 251, 229, 117, 228, 240, 119, 223, 200, 91, 197, 97, 246, 169, 67, 131, 202, 127, 199, 122, 63, 209, 46, 57, 181, 65, 21), (127, 81, 49, 87, 99, 135, 34, 75, 53, 225, 39, 108, 249, 171, 75, 34, 194, 210, 113, 2, 67, 72, 15, 188, 250, 65, 196, 114), (94, 185, 75, 233, 35, 156, 240, 94, 133, 77, 53, 134, 238, 180, 215, 110, 141, 70, 217, 84, 64, 35, 244, 186, 33, 137, 129, 217), (195, 70, 230, 92, 99, 111, 53, 237, 248, 25, 233, 224, 87, 32, 38, 90, 57, 161, 46, 53, 133, 9, 183, 223, 205, 93, 83, 81), (44, 241, 76, 85, 142, 134, 44, 239, 93, 24, 99, 171, 237, 52, 147, 89, 64, 41, 233, 194, 66, 10, 44, 143, 90, 79, 219, 118), (19, 202, 50, 226, 214, 203, 95, 121, 144, 4, 196, 3, 178, 163, 81, 208, 35, 179, 25, 100, 98, 247, 91, 146, 20, 205, 204, 186), (250, 213, 25, 8, 139, 63, 111, 137, 95, 82, 144, 24, 181, 194, 29, 116, 216, 121, 239, 187, 38, 78, 202, 185, 50, 199, 93, 146), (81, 7, 53, 236, 121, 165, 151, 85, 224, 120, 4, 100, 161, 148, 49, 227, 212, 102, 103, 58, 32, 82, 163, 91, 218, 151, 77, 125), (128, 23, 100, 175, 97, 27, 197, 99, 67, 26, 128, 128, 76, 41, 162, 120, 212, 107, 126, 3, 14, 228, 65, 142, 232, 181, 1, 13), (56, 51, 48, 89, 179, 37, 93, 143, 85, 80, 186, 132, 243, 89, 237, 6, 105, 193, 232, 175, 98, 162, 12, 79, 59, 227, 39, 149), (186, 164, 150, 6, 23, 246, 232, 174, 173, 29, 191, 98, 93, 179, 63, 77, 154, 53, 63, 178, 13, 237, 209, 146, 195, 177, 25, 80), (166, 56, 184, 16, 45, 117, 18, 135, 61, 114, 104, 83, 105, 52, 47, 192, 32, 20, 82, 215, 202, 71, 27, 161, 91, 97, 183, 130), (83, 240, 194, 9, 93, 67, 98, 33, 133, 86, 238, 238, 86, 118, 157, 101, 19, 172, 33, 18, 212, 79, 36, 59, 159, 128, 145, 232), (96, 160, 212, 8, 186, 194, 80, 36, 166, 55, 233, 113, 160, 163, 95, 5, 231, 176, 191, 99, 114, 82, 75, 205, 116, 163, 169, 55), (204, 78, 66, 108, 17, 44, 157, 221, 73, 31, 45, 223, 166, 186, 71, 195, 96, 148, 19, 94, 88, 223, 72, 156, 47, 232, 49, 180), (83, 69, 87, 26, 95, 233, 120, 165, 224, 135, 187, 28, 165, 68, 251, 85, 220, 0, 177, 19, 100, 101, 122, 230, 204, 222, 124, 178), (146, 114, 66, 213, 48, 50, 171, 53, 196, 130, 44, 156, 179, 80, 3, 209, 127, 76, 119, 6, 240, 103, 167, 69, 192, 69, 121, 240), (6, 217, 131, 111, 207, 65, 1, 247, 202, 132, 119, 74, 11, 243, 72, 169, 224, 144, 45, 218, 93, 253, 161, 132, 191, 73, 176, 126), (116, 18, 149, 78, 138, 127, 193, 128, 253, 196, 222, 251, 94, 78, 166, 189, 68, 167, 67, 9, 57, 225, 106, 66, 42, 153, 182, 8), (149, 94, 116, 111, 1, 243, 148, 167, 200, 203, 92, 53, 135, 73, 168, 64, 10, 48, 159, 4, 230, 142, 245, 69, 247, 156, 241, 45), (55, 240, 87, 240, 68, 215, 121, 152, 62, 49, 21, 93, 137, 187, 196, 70, 153, 101, 69, 70, 111, 78, 126, 43, 85, 226, 214, 252), (101, 254, 41, 109, 222, 80, 54, 145, 20, 57, 97, 152, 25, 4, 13, 246, 177, 3, 161, 1, 145, 243, 63, 84, 244, 187, 218, 4), (154, 139, 81, 14, 24, 107, 44, 94, 30, 19, 192, 56, 202, 4, 208, 17, 32, 121, 177, 166, 36, 36, 38, 41, 27, 165, 24, 39), (156, 5, 191, 24, 240, 63, 21, 18, 70, 34, 179, 245, 156, 168, 247, 87, 196, 186, 18, 142, 89, 75, 91, 80, 217, 86, 55, 14), (162, 1, 224, 82, 40, 196, 33, 2, 187, 227, 151, 205, 64, 130, 97, 242, 62, 133, 29, 23, 145, 116, 28, 162, 235, 92, 105, 104), (192, 37, 68, 116, 107, 11, 191, 239, 198, 225, 113, 188, 106, 206, 147, 97, 97, 107, 92, 200, 0, 55, 52, 119, 40, 39, 22, 233)))\n",
    "image = image / 255\n",
    "\n",
    "#image = np.expand_dims(image, axis=2) # axis=0 => (1, 28, 28) | axis=1 => (28, 1, 28) | axis=2 => (28, 28, 1)\n",
    "image5 = image.reshape(28 * 28)\n",
    "image5 = np.array((image5,) * 5)\n",
    "image = image.reshape(1, 28 * 28)\n",
    "print(image.shape)\n",
    "print(image5.shape)\n",
    "\n",
    "res = model.predict(image5)\n",
    "print(res)\n",
    "#print(dir(model))\n",
    "print(model.layers[0].input)\n",
    "print(model.layers[0].output)\n",
    "\n",
    "from keras.models import Model\n",
    "activation_model = Model(inputs=model.layers[0].input, outputs=[layer.output for layer in model.layers])\n",
    "\n",
    "# Получение активаций для входного изображения\n",
    "activations = activation_model.predict(image)\n",
    "\n",
    "for i, activation in enumerate(activations):\n",
    "    print(f\"Activation of layer {i}: shape {activation.shape}\")\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    w = layer.get_weights()\n",
    "    if not w: continue # dropout'ы не содержат весов\n",
    "    weights, biases = w\n",
    "    print(f\"Weights of layer {i}: shape {weights.shape}, biases shape {biases.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b3723c3-c49b-48d3-8738-c24d86a1e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "option = 3\n",
    "\n",
    "if option == 0:\n",
    "    model.save(\"trained_model.keras\")\n",
    "    print(\"saved #1\")\n",
    "if option == 1:\n",
    "    model.save(\"trained_model2.keras\")\n",
    "    print(\"saved #2\")\n",
    "\n",
    "if option in (2, 3):\n",
    "    print(\"load model...\")\n",
    "    if option == 2: model = load_model(\"trained_model.keras\")\n",
    "    if option == 3: model = load_model(\"trained_model2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
